{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6ybPlbaFPJVM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \".\""
      ],
      "metadata": {
        "id": "IPqJOUBkBysh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c udea-ai4eng-20242"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Kd9yqQB73S",
        "outputId": "ccfcede9-3f21-45b3-ac79-307a033c6c62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ./kaggle.json'\n",
            "Downloading udea-ai4eng-20242.zip to /content\n",
            " 55% 11.0M/20.1M [00:00<00:00, 111MB/s]\n",
            "100% 20.1M/20.1M [00:00<00:00, 151MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip udea-ai4eng-20242.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhtf4Ve4CR5C",
        "outputId": "3a5e578e-9347-4d71-901c-fcc6f87ea5ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  udea-ai4eng-20242.zip\n",
            "  inflating: submission_example.csv  \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fuzzywuzzy[speedup]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgMKe_VA0nve",
        "outputId": "0809a4f9-65c9-47e9-a856-c5c8fb8d0e95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-levenshtein>=0.12 (from fuzzywuzzy[speedup])\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.26.1 (from python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 fuzzywuzzy-0.18.0 python-levenshtein-0.26.1 rapidfuzz-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c65Eil3j2o0G",
        "outputId": "b12b11f0-c380-4edd-c616-0403f9d98a50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "z = pd.read_csv('train.csv')\n",
        "t = pd.read_csv('test.csv')\n",
        "\n",
        "labels = z[\"RENDIMIENTO_GLOBAL\"].values\n",
        "\n",
        "dts_labels = np.random.choice(labels, 296786, replace=False)\n",
        "\n",
        "\n",
        "source_cols = [i for i in z.columns if i!=\"RENDIMIENTO_GLOBAL\"]\n",
        "z = pd.concat((z[source_cols], t[source_cols]))\n",
        "z.index = range(len(z))\n",
        "\n",
        "\n",
        "mapBinary = {'Si': 1, 'S': 1, 'No': 0, 'N':0}\n",
        "binaryColumns = ['FAMI_TIENEINTERNET' , 'ESTU_PAGOMATRICULAPROPIO']\n",
        "\n",
        "for column in binaryColumns:\n",
        "    z[column] = z[column].map(mapBinary)\n",
        "\n",
        "variablesFaltantesBinaryCol = z[binaryColumns].isnull().sum()\n",
        "\n",
        "\n",
        "\n",
        "# Definir las columnas de interés\n",
        "columnas_de_interes = ['FAMI_TIENEINTERNET']\n",
        "datos_imputados = z\n",
        "\n",
        "# Iterar sobre las columnas de interés\n",
        "for columna in columnas_de_interes:\n",
        "    # Calcular la proporción de valores existentes\n",
        "    proporciones = datos_imputados[columna].value_counts(normalize=True)\n",
        "\n",
        "    # Calcular la proporción de 1 y 0\n",
        "    prop_1 = proporciones.get(1, 0)\n",
        "    prop_0 = proporciones.get(0, 0)\n",
        "\n",
        "    # Imputar los valores faltantes de forma aleatoria\n",
        "    datos_imputados[columna].fillna(np.random.choice([0, 1], p=[prop_0, prop_1]), inplace=True)\n",
        "# Llenar los valores faltantes en la columna 'ESTU_PAGOMATRICULAPROPIO' con '0'\n",
        "\n",
        "z['ESTU_PAGOMATRICULAPROPIO'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Diccionario para FAMI_ESTRATOVIVIENDA\n",
        "mapeo_estrato = {'Sin Estrato': 0, 'Estrato 1': 1, 'Estrato 2': 2, 'Estrato 3': 3, 'Estrato 4': 4, 'Estrato 5': 5, 'Estrato 6': 6}\n",
        "# Aplicar map a las columnas con el diccionario\n",
        "z['FAMI_ESTRATOVIVIENDA'] = z['FAMI_ESTRATOVIVIENDA'].map(mapeo_estrato)\n",
        "\n",
        "faltantesEstrato = z['FAMI_ESTRATOVIVIENDA'].isnull().sum()\n",
        "\n",
        "# Calcular la media y la mediana de FAMI_ESTRATOVIVIENDA\n",
        "media_estrato = z['FAMI_ESTRATOVIVIENDA'].mean()\n",
        "\n",
        "# Imputar los valores faltantes con la media\n",
        "z['FAMI_ESTRATOVIVIENDA'] = z['FAMI_ESTRATOVIVIENDA'].fillna(media_estrato)\n",
        "\n",
        "\n",
        "\n",
        "z['FAMI_ESTRATOVIVIENDA'] = z['FAMI_ESTRATOVIVIENDA'].astype(int)\n",
        "\n",
        "\n",
        "\n",
        "# Definir el mapeo de categorías a valores numéricos para cada columna\n",
        "mapeo_valores_matricula = {\n",
        "    'No pagó matrícula': 0,\n",
        "    'Menos de 500 mil': 1,\n",
        "    'Entre 500 mil y menos de 1 millón': 2,\n",
        "    'Entre 1 millón y menos de 2.5 millones': 3,\n",
        "    'Entre 2.5 millones y menos de 4 millones': 4,\n",
        "    'Entre 4 millones y menos de 5.5 millones': 5,\n",
        "    'Entre 5.5 millones y menos de 7 millones': 6,\n",
        "    'Más de 7 millones': 7\n",
        "}\n",
        "\n",
        "mapeo_valores_horas_trabajo = {\n",
        "    '0': 0,\n",
        "    'Menos de 10 horas': 1,\n",
        "    'Entre 11 y 20 horas': 2,\n",
        "    'Entre 21 y 30 horas': 3,\n",
        "    'Más de 30 horas': 4\n",
        "}\n",
        "\n",
        "\n",
        "# Convertir las columnas a formato numérico utilizando el mapeo\n",
        "z['ESTU_VALORMATRICULAUNIVERSIDAD'] = z['ESTU_VALORMATRICULAUNIVERSIDAD'].map(mapeo_valores_matricula)\n",
        "z['ESTU_HORASSEMANATRABAJA'] = z['ESTU_HORASSEMANATRABAJA'].map(mapeo_valores_horas_trabajo)\n",
        "\n",
        "\n",
        "# Calcular la media total de la columna ESTU_VALORMATRICULAUNIVERSIDAD\n",
        "media_valormatricula = z['ESTU_VALORMATRICULAUNIVERSIDAD'].mean()\n",
        "\n",
        "# Remplazar los valores faltantes en ESTU_VALORMATRICULAUNIVERSIDAD con la media total\n",
        "z['ESTU_VALORMATRICULAUNIVERSIDAD'].fillna(media_valormatricula, inplace=True)\n",
        "\n",
        "# Obtener los valores únicos en la columna ESTU_HORASSEMANATRABAJA\n",
        "valores_horas_trabajo = z['ESTU_HORASSEMANATRABAJA'].dropna().unique()\n",
        "\n",
        "# Calcular la cantidad de valores faltantes en ESTU_HORASSEMANATRABAJA\n",
        "num_valores_faltantes = z['ESTU_HORASSEMANATRABAJA'].isnull().sum()\n",
        "\n",
        "\n",
        "media_trabaja = z['ESTU_HORASSEMANATRABAJA'].mean()\n",
        "z['ESTU_HORASSEMANATRABAJA'].fillna(media_trabaja, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Eliminar de los valores de las columnas FAMI_EDUCACIONPADRE Y FAMI_EDUCACIONMADRE las palabras \"Incompleto\", \"completo\",\n",
        "def limpiar_cadena(cadena):\n",
        "  if isinstance(cadena, str):\n",
        "    cadena = cadena.replace(\"incompleta\", \"\").replace(\"incompleto\", \"\").replace(\"completo\", \"\").replace(\"completa\", \"\").strip()\n",
        "  return cadena\n",
        "\n",
        "# Aplicar la función a las columnas FAMI_EDUCACIONPADRE y FAMI_EDUCACIONMADRE\n",
        "z['FAMI_EDUCACIONPADRE'] = z['FAMI_EDUCACIONPADRE'].apply(limpiar_cadena)\n",
        "z['FAMI_EDUCACIONMADRE'] = z['FAMI_EDUCACIONMADRE'].apply(limpiar_cadena)\n",
        "\n",
        "\n",
        "\n",
        "# Obtener los valores más frecuentes para cada columna\n",
        "top_padre = z['FAMI_EDUCACIONPADRE'].mode()[0]\n",
        "top_madre = z['FAMI_EDUCACIONMADRE'].mode()[0]\n",
        "\n",
        "# Rellenar los valores faltantes con los valores más frecuentes\n",
        "z['FAMI_EDUCACIONPADRE'].fillna(top_padre, inplace=True)\n",
        "z['FAMI_EDUCACIONMADRE'].fillna(top_madre, inplace=True)\n",
        "\n",
        "\n",
        "# Calcula la moda para las columnas seleccionadas\n",
        "moda_padre = z['FAMI_EDUCACIONPADRE'].mode()[0]\n",
        "moda_madre = z['FAMI_EDUCACIONMADRE'].mode()[0]\n",
        "\n",
        "# Rellena los valores faltantes con la moda\n",
        "z['FAMI_EDUCACIONPADRE'].fillna(moda_padre, inplace=True)\n",
        "z['FAMI_EDUCACIONMADRE'].fillna(moda_madre, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Aplicar one-hot encoding a las columnas 'FAMI_EDUCACIONPADRE' y 'FAMI_EDUCACIONMADRE'\n",
        "z = pd.get_dummies(z, columns=['FAMI_EDUCACIONPADRE', 'FAMI_EDUCACIONMADRE'], prefix=['PADRE_EDUCACION', 'MADRE_EDUCACION'])\n",
        "\n",
        "# Asignar 0 para False y 1 para True en las columnas generadas por one-hot encoding\n",
        "z.replace({True: 1, False: 0}, inplace=True)\n",
        "\n",
        "# Lista de columnas que se desean convertir de float a int\n",
        "columnas_float_a_entero = ['ESTU_VALORMATRICULAUNIVERSIDAD', 'ESTU_HORASSEMANATRABAJA',\n",
        "                           'FAMI_TIENEINTERNET',\n",
        "                           'ESTU_PAGOMATRICULAPROPIO', 'FAMI_ESTRATOVIVIENDA']\n",
        "\n",
        "# Convertir las columnas de float a enteros\n",
        "z[columnas_float_a_entero] = z[columnas_float_a_entero].astype(int)\n",
        "\n",
        "\n",
        "\n",
        "departamentosRegion = {\n",
        "    'Caribe': ['ATLANTICO', 'BOLIVAR', 'CORDOBA', 'CESAR' 'LA GUAJIRA', 'MAGDALENA', 'SUCRE', 'SAN ANDRES'],\n",
        "    'Andina': ['ANTIOQUIA', 'BOYACA', 'CUNDINAMARCA', 'RISARALDA', 'TOLIMA', 'CALDAS', 'CAUCA', 'HUILA', 'NORTE SANTANDER', 'QUINDIO', 'SANTANDER', 'BOGOTA'],\n",
        "    'Pacifica': ['CHOCO', 'NARIÑO', 'VALLE'],\n",
        "    'Orinoquia': ['ARAUCA', 'CASANARE', 'META'],\n",
        "    'Amazonica': ['AMAZONAS', 'CAQUETA', 'GUAVIARE', 'VAUPES', 'PUTUMAYO'],\n",
        "}\n",
        "# Prefijo para los nombres de las nuevas columnas\n",
        "prefijo_columnas = 'DEPARTAMENTO_'\n",
        "\n",
        "# Crear columnas para cada región y asignar los departamentos correspondientes\n",
        "for region, departamentos in departamentosRegion.items():\n",
        "    z[prefijo_columnas + region.replace(' ', '_').upper()] = z['ESTU_PRGM_DEPARTAMENTO'].apply(lambda x: x if x in departamentos else None)\n",
        "\n",
        "# Eliminar la columna original ESTU_PRGM_DEPARTAMENTO\n",
        "z.drop(columns=['ESTU_PRGM_DEPARTAMENTO'], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "map_recurrencia_caribe = {'SAN ANDRES': 1, 'LA GUAJIRA': 2, 'CESAR': 3, 'SUCRE': 4, 'MAGDALENA': 5, 'CORDOBA': 6, 'BOLIVAR': 7, 'NORTE SANTANDER': 8, 'ATLANTICO': 9}\n",
        "map_recurrencia_andina = {'QUINDIO': 1, 'HUILA': 2, 'CAUCA': 3, 'CALDAS': 4, 'TOLIMA': 5, 'RISARALDA': 6, 'CUNDINAMARCA': 7, 'BOYACA': 8, 'SANTANDER': 9, 'ANTIOQUIA': 10, 'BOGOTA': 11}\n",
        "map_recurrencia_pacifica = {'CHOCO': 1, 'NARIÑO': 2, 'VALLE': 3}\n",
        "map_recurrencia_orinoquia = {'ARAUCA': 1, 'CASANARE': 2, 'META': 3}\n",
        "map_recurrencia_amazonica = {'VAUPES': 1, 'GUAVIARE': 2, 'AMAZONAS': 3, 'PUTUMAYO': 4, 'CAQUETA': 5}\n",
        "\n",
        "\n",
        "z['DEPARTAMENTO_CARIBE'] = z['DEPARTAMENTO_CARIBE'].map(map_recurrencia_caribe)\n",
        "z['DEPARTAMENTO_ANDINA'] = z['DEPARTAMENTO_ANDINA'].map(map_recurrencia_andina)\n",
        "z['DEPARTAMENTO_PACIFICA'] = z['DEPARTAMENTO_PACIFICA'].map(map_recurrencia_pacifica)\n",
        "z['DEPARTAMENTO_ORINOQUIA'] = z['DEPARTAMENTO_ORINOQUIA'].map(map_recurrencia_orinoquia)\n",
        "z['DEPARTAMENTO_AMAZONICA'] = z['DEPARTAMENTO_AMAZONICA'].map(map_recurrencia_amazonica)\n",
        "\n",
        "columnas_reemplazar_departamentos = ['DEPARTAMENTO_CARIBE', 'DEPARTAMENTO_ANDINA', 'DEPARTAMENTO_PACIFICA', 'DEPARTAMENTO_ORINOQUIA', 'DEPARTAMENTO_AMAZONICA']\n",
        "z[columnas_reemplazar_departamentos] = z[columnas_reemplazar_departamentos].fillna(0).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "# Función para normalizar el texto\n",
        "def normalize_text(text):\n",
        "    text = text.lower()  # Convertir a minúsculas\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Normalizar la columna 'ESTU_PRGM_ACADEMICO'\n",
        "z['ESTU_PRGM_ACADEMICO_NORMALIZADO'] = z['ESTU_PRGM_ACADEMICO'].apply(normalize_text)\n",
        "\n",
        "# Diccionario para almacenar mapeos\n",
        "text_map = {}\n",
        "\n",
        "# Iterar sobre cada entrada única en la columna normalizada\n",
        "for text in z['ESTU_PRGM_ACADEMICO_NORMALIZADO'].unique():\n",
        "    match = process.extractOne(text, text_map.keys(), score_cutoff=90)\n",
        "\n",
        "    if match:  # Verificamos que haya una coincidencia válida\n",
        "        best_match, score = match  # Desempaquetamos solo si existe\n",
        "        text_map[text] = text_map[best_match]\n",
        "    else:\n",
        "        # Si no hay match, el texto es considerado una nueva entrada\n",
        "        text_map[text] = text\n",
        "\n",
        "# Aplicar el mapeo de agrupación al DataFrame\n",
        "z['ESTU_PRGM_ACADEMICO_LIMPIO'] = z['ESTU_PRGM_ACADEMICO_NORMALIZADO'].map(text_map)\n",
        "\n",
        "\n",
        "\n",
        "# Lista de palabras irrelevantes (stop words) que queremos eliminar\n",
        "stop_words = [\n",
        "    'profesional', 'universitario', 'en', 'la',\n",
        "    'con', 'enfasis', 'para', 'industria', 'basica'\n",
        "]\n",
        "\n",
        "# Función para eliminar palabras irrelevantes\n",
        "def remove_stop_words(text):\n",
        "    # Dividimos el texto en palabras y eliminamos las que coincidan con las stop words\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Aplicamos la función para eliminar términos irrelevantes\n",
        "z['ESTU_PRGM_ACADEMICO_REDUCIDO'] = z['ESTU_PRGM_ACADEMICO_LIMPIO'].apply(remove_stop_words)\n",
        "\n",
        "# Diccionario para almacenar mapeos\n",
        "text_map = {}\n",
        "\n",
        "# Iterar sobre cada entrada única en la columna reducida\n",
        "for text in z['ESTU_PRGM_ACADEMICO_REDUCIDO'].unique():\n",
        "    # Usar fuzzywuzzy para encontrar el mejor match con un umbral de similitud\n",
        "    match = process.extractOne(text, text_map.keys(), score_cutoff=85)\n",
        "\n",
        "    if match:  # Verificamos que match no sea None\n",
        "        best_match, score = match  # Desempaquetamos la tupla solo si match es válido\n",
        "        text_map[text] = text_map[best_match]  # Asignar la entrada al grupo ya existente\n",
        "    else:\n",
        "        # Si no hay match, agregarlo como nueva entrada en el mapa\n",
        "        text_map[text] = text\n",
        "\n",
        "# Crear una columna con las entradas agrupadas\n",
        "z['ESTU_PRGM_ACADEMICO_FINAL'] = z['ESTU_PRGM_ACADEMICO_REDUCIDO'].map(text_map)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Diccionario de categorías\n",
        "categorias = {\n",
        "    \"Ciencias de la Salud\": [\n",
        "        \"enfermeria\", \"psicologia\", \"medicina veterinaria\", \"odontologia\", \"quimica farmaceutica\",\n",
        "        \"instrumentacion quirurgica\", \"fisioterapia\", \"farmacia\", \"optometria\", \"bacteriologia\",\n",
        "        \"terapia respiratoria\", \"fonoaudiologia\"\n",
        "    ],\n",
        "    \"Ingenierías\": [\n",
        "        \"ingenieria mecanica\", \"ingenieria industrial\", \"ingenieria civil\", \"ingeniera multimedia\"\n",
        "    ],\n",
        "    \"Administración y Negocios\": [\n",
        "        \"administracion de empresas\", \"administracin salud ocupacional\", \"administracin financiera\",\n",
        "        \"hoteleria y turismo\", \"negocios internacionales\", \"agronegocios\", \"administracion de calidad\",\n",
        "        \"administracion servicio\"\n",
        "    ],\n",
        "    \"Ciencias Sociales y Humanidades\": [\n",
        "        \"derecho\", \"comunicacion social\", \"ciencia politica\", \"trabajo social\", \"sociologia\",\n",
        "        \"relaciones internacionales\", \"jurisprudencia\", \"estudios literarios\", \"historia\",\n",
        "        \"licenciatura ciencias sociales\", \"licenciatura pedagogia infantil\", \"licenciatura educacion humanidadesingles\"\n",
        "    ],\n",
        "    \"Artes y Diseño\": [\n",
        "        \"maestro msica\", \"comunicacion audiovisual\", \"diseo industrial\", \"diseo grafico\",\n",
        "        \"diseo visual\", \"arte danzario\", \"artes plasticas\"\n",
        "    ],\n",
        "    \"Ciencias Exactas y Naturales\": [\n",
        "        \"estadistica\", \"zootecnia\", \"quimica farmaceutica\", \"agronomia\", \"geologia\"\n",
        "    ],\n",
        "    \"Otras\": [\n",
        "        \"mercadeo y publicidad\", \"arquitectura\", \"economia\", \"criminalistica\", \"entrenamiento deportivo\",\n",
        "        \"traduccion inglesfrancesespaol\", \"antropologia\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Crear un diccionario inverso para mapear programas individuales a su categoría\n",
        "mapeo_programas = {programa: categoria for categoria, programas in categorias.items() for programa in programas}\n",
        "\n",
        "# Función para mapear cada programa académico a su categoría\n",
        "z['CATEGORIA_PRGM_ACADEMICO'] = z['ESTU_PRGM_ACADEMICO_FINAL'].map(mapeo_programas)\n",
        "\n",
        "\n",
        "\n",
        "columns_to_drop = ['ESTU_PRGM_ACADEMICO_NORMALIZADO', 'ESTU_PRGM_ACADEMICO_LIMPIO', 'ESTU_PRGM_ACADEMICO_REDUCIDO', 'ESTU_PRGM_ACADEMICO_FINAL', 'ESTU_PRGM_ACADEMICO']\n",
        "z = z.drop(columns=columns_to_drop)\n",
        "\n",
        "\n",
        "z = pd.get_dummies(z, columns=['CATEGORIA_PRGM_ACADEMICO'], prefix=['PRGM_ACADEMICO'])\n",
        "\n",
        "\n",
        "z.replace({True: 1, False: 0}, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "columnas_float_a_entero = z.select_dtypes(include=['float64']).columns.tolist()\n",
        "\n",
        "# Convertir las columnas de float a enteros\n",
        "z[columnas_float_a_entero] = z[columnas_float_a_entero].astype(int)\n",
        "\n",
        "\n",
        "originalData = pd.read_csv('train.csv')\n",
        "lentr = len(originalData)\n",
        "\n",
        "Xtrk, ytrk = z.iloc[:lentr].values, originalData[\"RENDIMIENTO_GLOBAL\"].values\n",
        "Xtsk  = z.iloc[lentr:].values\n",
        "\n",
        "\n",
        "\n",
        "n = int(len(Xtrk)*0.8)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mWv_kUeICm1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e43b7d-8518-489b-e88d-f4b3b9b8bf06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-027d61b213a2>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  datos_imputados[columna].fillna(np.random.choice([0, 1], p=[prop_0, prop_1]), inplace=True)\n",
            "<ipython-input-8-027d61b213a2>:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  z['ESTU_PAGOMATRICULAPROPIO'].fillna(0, inplace=True)\n",
            "<ipython-input-8-027d61b213a2>:103: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  z['ESTU_VALORMATRICULAUNIVERSIDAD'].fillna(media_valormatricula, inplace=True)\n",
            "<ipython-input-8-027d61b213a2>:113: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  z['ESTU_HORASSEMANATRABAJA'].fillna(media_trabaja, inplace=True)\n",
            "<ipython-input-8-027d61b213a2>:134: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  z['FAMI_EDUCACIONPADRE'].fillna(top_padre, inplace=True)\n",
            "<ipython-input-8-027d61b213a2>:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  z['FAMI_EDUCACIONMADRE'].fillna(top_madre, inplace=True)\n",
            "<ipython-input-8-027d61b213a2>:152: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  z.replace({True: 1, False: 0}, inplace=True)\n",
            "<ipython-input-8-027d61b213a2>:315: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  z.replace({True: 1, False: 0}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Dividir los índices de entrenamiento y validación\n",
        "idxs = np.random.permutation(len(Xtrk))\n",
        "idxs_trm = idxs[:n]\n",
        "idxs_tsm = idxs[n:]\n",
        "\n",
        "# Crear los conjuntos de entrenamiento y validación\n",
        "Xtrm = Xtrk[idxs_trm]\n",
        "ytrm = ytrk[idxs_trm]\n",
        "\n",
        "Xtsm = Xtrk[idxs_tsm]\n",
        "ytsm = ytrk[idxs_tsm]\n",
        "\n",
        "# Crear y entrenar el modelo Random Forest\n",
        "model = RandomForestClassifier(n_estimators=500, max_depth=10, random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(Xtrm, ytrm)\n",
        "\n",
        "# Hacer predicciones en el conjunto de test\n",
        "y_pred = model.predict(Xtsk)\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = accuracy_score(dts_labels, y_pred)\n"
      ],
      "metadata": {
        "id": "atYrdQwL2WVu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submissiondf = t[[\"ID\"]]\n",
        "submissiondf['RENDIMIENTO_GLOBAL'] = y_pred.flatten()\n",
        "\n",
        "\n",
        "submissiondf.to_csv('Entregakaggle.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "OYFzA6f96ZE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a5c956-aefa-47bf-e371-fa78d166383d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-80c3ea5f0100>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submissiondf['RENDIMIENTO_GLOBAL'] = y_pred.flatten()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head Entregakaggle.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV2OaUdA6dFt",
        "outputId": "057fe7c0-1177-4f72-83ae-8902a9029719"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID,RENDIMIENTO_GLOBAL\n",
            "550236,bajo\n",
            "98545,medio-alto\n",
            "499179,alto\n",
            "782980,bajo\n",
            "785185,bajo\n",
            "58495,bajo\n",
            "705444,alto\n",
            "557548,alto\n",
            "519909,bajo\n"
          ]
        }
      ]
    }
  ]
}